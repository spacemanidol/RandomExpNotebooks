{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c8347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import openai\n",
    "import ir_datasets\n",
    "openai.api_key = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MSMARCOV2_passages_random_1000.jsonl','r') as f:\n",
    "    with open('evaluated-MSMARCOV2-passage-quality.jsonl','w') as w:\n",
    "        for l in f:\n",
    "            j = json.loads(l)\n",
    "            our_model = \"gpt-4\"\n",
    "            prompt = 'Below is an instruction that describes a task, paired with an input that providesfurther context. Write a response that appropriately completes the request.\\n\\n'\n",
    "            prompt += '### Instruction: \\n\\n You are part of a serch engine which helps users find relevant context passages given their queries. As part of the index generation process we are evaluating the quality of passages that could occur on a search results page.'\n",
    "            prompt += 'In order to meet user needs it is important to ensure the context passages state clearly what they are talking about, for example, if a passage is reviewing a product, it must say what the product is. Otherwise there is a risk that we are taking the review of one product, but the person who is reading it thinks it is talking about a different product, because the search engine accidentally picked the wrong passage.\\n'\n",
    "            prompt += 'Read the context passage and rate it on a scale of 0 to 100, where 0 means that the passage is very unclear and confusing due to lack of context, and 100 means that the passage is very clear and informative due to providing sufficient context. Please include your reasoning and respond in well formed json.'\n",
    "            prompt += 'Consider the following factors when rating the passage:\\n 1.Does the passage state the main topic or question that it addresses? \\n 2. Does the passage provide any background information or definitions that are necessary to understand the main points? 3. Does the passage avoid using jargon or technical terms that are not explained or familiar to the intended audience?'\n",
    "            prompt += '### Input:\\n\\n'\n",
    "            prompt += 'context passage:{}\\n\\n'.format(j['passage'])\n",
    "            prompt += '### Response: \\n'\n",
    "            message=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=our_model,\n",
    "                max_tokens=100,\n",
    "                temperature=0.8,\n",
    "                messages = message)\n",
    "            print(response)\n",
    "            j1 = json.loads(response['choices'][0]['message']['content'])\n",
    "            j['rating'] = j1['rating']\n",
    "            j['reasoning'] = j1['reasoning']\n",
    "            w.write(\"{}\\n\".format(json.dumps(j)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "Example 1:\n",
    "Document: We don't know a lot about the effects of caffeine\n",
    "during pregnancy on you and your baby. So it's best to limit the\n",
    "amount you get each day. If you are pregnant, limit caffeine to\n",
    "200 milligrams each day. This is about the amount in 1Â½ 8-ounce\n",
    "cups of coffee or one 12-ounce cup of coffee.\n",
    "Good Question: How much caffeine is ok for a pregnant woman\n",
    "to have?\n",
    "Bad Question: Is a little caffeine ok during pregnancy?\n",
    "Example 2:\n",
    "Document: Passiflora herbertiana. A rare passion fruit native to\n",
    "Australia. Fruits are green-skinned, white fleshed, with an\n",
    "unknown edible rating. Some sources list the fruit as edible, sweet\n",
    "and tasty, while others list the fruits as being bitter and inedible.\n",
    "Good Question: What is Passiflora herbertiana (a rare passion\n",
    "fruit) and how does it taste like?\n",
    "Bad Question: What fruit is native to Australia?\n",
    "Example 3:\n",
    "Document: The Canadian Armed Forces. 1 The first large-scale\n",
    "Canadian peacekeeping mission started in Egypt on November 24,\n",
    "1956. 2 There are approximately 65,000 Regular Force and 25,000\n",
    "reservist members in the Canadian military. 3 In Canada, August 9\n",
    "is designated as National Peacekeepers' Day. Good Question: Information on the Canadian Armed Forces size\n",
    "and history. Bad Question: How large is the Canadian military?\n",
    "Example 4:\n",
    "Document: {document_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4434e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image.exceptions import (\n",
    "    PDFInfoNotInstalledError,\n",
    "    PDFPageCountError,\n",
    "    PDFSyntaxError\n",
    ")\n",
    "images = convert_from_path('/home/belval/example.pdf')\n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "import subprocess\n",
    "from subprocess import STDOUT, check_call\n",
    "import os\n",
    "import base64\n",
    "import camelot as cam\n",
    "\n",
    "@st.cache\n",
    "def gh():\n",
    "    proc = subprocess.Popen('apt-get install -y ghostscript', shell=True, stdin=None, stdout=open(os.devnull,'wb'), stderr=STDOUT, executable=\"/bin/bash\")\n",
    "\n",
    "gh()\n",
    "\n",
    "st.title(\"Extract Tables from PDFs\")\n",
    "\n",
    "input_pdf = st.file_uploader(label=\"Upload PDF here\",type='pdf')\n",
    "\n",
    "st.markdown(\"### Page Number\")\n",
    "\n",
    "page_number = st.text_input(\"Enter the page # from where you want the table\", value=1)\n",
    "\n",
    "if input_pdf is not None:\n",
    "    \n",
    "    with open(\"input.pdf\",\"wb\") as f:\n",
    "        base64_pdf = base64.b64encode(input_pdf.read()).decode('utf-8')\n",
    "        f.write(base64.b64decode(base64_pdf))\n",
    "    f.close()\n",
    "\n",
    "    table = cam.read_pdf(\"input.pdf\",pages = page_number, flavor = 'stream')\n",
    "    \n",
    "    st.markdown(\"## Number of Tables\")\n",
    "    \n",
    "    st.write(table)\n",
    "    \n",
    "    if len(table)>0:\n",
    "        \n",
    "        option = st.selectbox(label=\"Select the table to be displayed\", options = range(len(table)+1))\n",
    "        \n",
    "        st.markdown(\"### Output Table\")\n",
    "        \n",
    "        st.dataframe(table[int(option)-1].df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
